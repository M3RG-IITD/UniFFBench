generic:
  min_epochs: 50
  max_epochs: 100
debug:
  accelerator: cpu
  limit_train_batches: 10
  limit_val_batches: 10
  log_every_n_steps: 1
  max_epochs: 2
experiment:
  accelerator: cuda
  strategy:
    class_path: pytorch_lightning.strategies.DDPStrategy
    init_args:
      process_group_backend: "gloo"
      find_unused_parameters: true
callbacks:
  - class_path: pytorch_lightning.callbacks.EarlyStopping
    init_args:
      patience: 10
      monitor: val_denoise_epoch
      mode: min
      verbose: True
      check_finite: False
  - class_path: matsciml.lightning.callbacks.GradientCheckCallback
  - class_path: matsciml.lightning.callbacks.ExponentialMovingAverageCallback
    init_args:
      decay: 0.99
  - class_path: matsciml.lightning.callbacks.ManualGradientClip
    init_args:
      value: 10.0
      algorithm: "norm"
  - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    init_args:
      logging_interval: step
loggers:
  - class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      log_model: "all"
      project: "matsciml-uip-eval-pretraining"
      entity: "m3rg"
      mode: "online"
      name: null
      tags:
        - pretraining
        - noisy-nodes
